{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ LLMOps for Production RAG\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/unionai-oss/llmops-production-rag/blob/main/workshop.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Welcome to the LLMOps for Production RAG workshop! In this workshop, we will cover:\n",
    "\n",
    "1. Creating a baseline RAG pipeline\n",
    "2. Bootstrapping an evaluation dataset\n",
    "3. RAG Hyperparameter Optimization\n",
    "\n",
    "## ðŸ“¦ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/unionai-oss/llmops-production-rag.git\n",
    "    %cd /content/llmops-production-rag\n",
    "    !uv pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While dependencies are being installed, create an account on Union Serverless:\n",
    "\n",
    "ðŸ‘‰ https://signup.union.ai/\n",
    "\n",
    "Go to the Union Serverless dashboard to make sure you can check out the UI:\n",
    "\n",
    "ðŸ‘‰ https://serverless.union.ai/\n",
    "\n",
    "Then, login to Union on this notebook session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create login --auth device-flow --serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Create OpenAI API Key Secret on Union\n",
    "\n",
    "First go to https://platform.openai.com/account/api-keys and create an OpenAI API key.\n",
    "\n",
    "Then, run the following command to make the secret accessible on Union:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create secret openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union get secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have issues with the secret, you can delete it by uncommenting the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!union delete secret openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—‚ï¸ Creating a Baseline RAG Pipeline\n",
    "\n",
    "Create the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import union\n",
    "from typing import Optional\n",
    "from llmops_rag.vector_store import create_knowledge_base, chunk_and_embed_documents\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def create_vector_store(\n",
    "    root_url_tags_mapping: Optional[dict] = None,\n",
    "    splitter: str = \"character\",\n",
    "    chunk_size: int = 2048,\n",
    "    limit: Optional[int | float] = None,\n",
    "    embedding_model: Optional[str] = \"text-embedding-ada-002\",\n",
    "    exclude_patterns: Optional[list[str]] = None,\n",
    ") -> union.FlyteDirectory:\n",
    "    \"\"\"\n",
    "    Workflow for creating the vector store knowledge base.\n",
    "    \"\"\"\n",
    "    docs = create_knowledge_base(\n",
    "        root_url_tags_mapping=root_url_tags_mapping,\n",
    "        limit=limit,\n",
    "        exclude_patterns=exclude_patterns,\n",
    "    )\n",
    "    vector_store = chunk_and_embed_documents(\n",
    "        documents=docs,\n",
    "        splitter=splitter,\n",
    "        chunk_size=chunk_size,\n",
    "        embedding_model=embedding_model,\n",
    "    )\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute this workflow, let's create a `UnionRemote` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = union.UnionRemote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we execute the `create_vector_store` workflow with the `.execute()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_execution = remote.execute(\n",
    "    create_vector_store,\n",
    "    inputs=dict(\n",
    "        limit=10,\n",
    "        chunk_size=512,\n",
    "        splitter=\"character\",\n",
    "    ),\n",
    ")\n",
    "vector_store_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ Note: The above command will take a few minutes to complete since we're building our container for the first time.\n",
    "\n",
    "Then implement a basic RAG pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import union\n",
    "from typing import Optional\n",
    "from llmops_rag.vector_store import VectorStore\n",
    "from llmops_rag.rag_basic import retrieve, generate\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def rag_basic(\n",
    "    questions: list[str],\n",
    "    vector_store: union.FlyteDirectory = VectorStore.query(),  # ðŸ‘ˆ this uses the vector store artifact by default\n",
    "    embedding_model: str = \"text-embedding-ada-002\",\n",
    "    generation_model: str = \"gpt-4o-mini\",\n",
    "    search_type: str = \"similarity\",\n",
    "    rerank: bool = False,\n",
    "    num_retrieved_docs: int = 20,\n",
    "    num_docs_final: int = 5,\n",
    "    prompt_template: Optional[str] = None,\n",
    ") -> list[str]:\n",
    "    contexts = retrieve(\n",
    "        questions=questions,\n",
    "        vector_store=vector_store,\n",
    "        embedding_model=embedding_model,\n",
    "        search_type=search_type,\n",
    "        rerank=rerank,\n",
    "        num_retrieved_docs=num_retrieved_docs,\n",
    "        num_docs_final=num_docs_final,\n",
    "    )\n",
    "    return generate(\n",
    "        questions=questions,\n",
    "        contexts=contexts,\n",
    "        generation_model=generation_model,\n",
    "        prompt_template=prompt_template,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = union.UnionRemote()\n",
    "rag_basic_execution = remote.execute(\n",
    "    rag_basic,\n",
    "    inputs=dict(\n",
    "        questions=[\"How do I read and write a pandas dataframe to csv format?\"],\n",
    "    ),\n",
    ")\n",
    "rag_basic_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the output of the rag pipeline execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_basic_execution = remote.sync(remote.wait(rag_basic_execution))\n",
    "print(rag_basic_execution.outputs[\"o0\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ Maintaining a Fresh Vector Store\n",
    "\n",
    "Let's use launch plan schedules to maintain a fresh vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import flytekit as fl\n",
    "\n",
    "\n",
    "union.LaunchPlan.CACHE = {}\n",
    "schedule_vector_store_lp = union.LaunchPlan.get_or_create(\n",
    "    name=\"schedule_vector_store_lp\",\n",
    "    workflow=create_vector_store,\n",
    "    default_inputs=dict(\n",
    "        limit=10,\n",
    "        chunk_size=512,\n",
    "        splitter=\"character\",\n",
    "    ),\n",
    "    schedule=fl.FixedRate(\n",
    "        duration=timedelta(minutes=2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"workshop-v0\"\n",
    "remote = union.UnionRemote()\n",
    "\n",
    "registered_schedule_vector_store_lp = remote.register_launch_plan(\n",
    "    schedule_vector_store_lp,\n",
    "    version=version,\n",
    ")\n",
    "remote.activate_launchplan(registered_schedule_vector_store_lp.id)\n",
    "print(\"ðŸš€ Launch plan activated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.deactivate_launchplan(registered_schedule_vector_store_lp.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the Serverless dashboard to see the schedule in action.\n",
    "\n",
    "Make sure to deactivate the launchplan in the UI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’» Run RAG pipeline with Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def add_message(history, message):\n",
    "    if message is not None:\n",
    "        history.append({\"role\": \"user\", \"content\": message})\n",
    "    return history, gr.Textbox(value=None, interactive=False)\n",
    "\n",
    "\n",
    "def bot(history: list):\n",
    "    remote = union.UnionRemote()\n",
    "    last_user_message = [msg for msg in history if msg[\"role\"] == \"user\"][-1][\"content\"]\n",
    "    execution = remote.execute(rag_basic, inputs={\"questions\": [last_user_message]})\n",
    "    url = remote.generate_console_url(execution)\n",
    "    print(f\"ðŸš€ Union Serverless execution url: {url}\")\n",
    "\n",
    "    answers = None\n",
    "    execution = remote.wait(execution, poll_interval=timedelta(seconds=2))\n",
    "    answers = execution.outputs[\"o0\"]\n",
    "\n",
    "    if answers is None:\n",
    "        raise RuntimeError(\"Failed to get answer\")\n",
    "    \n",
    "    answer = answers[0]\n",
    "\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    history[-1][\"content\"] += answer\n",
    "    yield history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(elem_id=\"chatbot\", type=\"messages\")\n",
    "\n",
    "    chat_input = gr.Textbox(\n",
    "        interactive=True,\n",
    "        placeholder=\"How do I write a dataframe to csv?\",\n",
    "        show_label=False,\n",
    "    )\n",
    "    chat_msg = chat_input.submit(\n",
    "        add_message, [chatbot, chat_input], [chatbot, chat_input]\n",
    "    )\n",
    "    bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n",
    "    bot_msg.then(lambda: gr.Textbox(interactive=True), None, [chat_input])\n",
    "\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¥¾ Bootstrapping an Evaluation Dataset\n",
    "\n",
    "Then generate a question and answer dataset. This will use the raw knowledge base we created\n",
    "in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Annotated\n",
    "\n",
    "import union\n",
    "from llmops_rag.create_qa_dataset import generate_qa_datapoints, create_dataset, QuestionAndAnswerDataset\n",
    "from llmops_rag.document import CustomDocument\n",
    "from llmops_rag.vector_store import KnowledgeBase\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def create_qa_dataset(\n",
    "    documents: list[CustomDocument] = KnowledgeBase.query(),\n",
    "    n_questions_per_doc: int = 1,\n",
    "    n_answers_per_question: int = 5,\n",
    ") -> Annotated[union.FlyteFile, QuestionAndAnswerDataset]:\n",
    "    partial_task = functools.partial(\n",
    "        generate_qa_datapoints,\n",
    "        n_questions_per_doc=n_questions_per_doc,\n",
    "        n_answers_per_question=n_answers_per_question,\n",
    "    )\n",
    "    questions_and_answers = union.map_task(partial_task)(flyte_doc=documents)\n",
    "    return create_dataset(questions_and_answers, n_answers_per_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = union.UnionRemote()\n",
    "qa_dataset_execution = remote.execute(\n",
    "    create_qa_dataset,\n",
    "    inputs={\"n_questions_per_doc\": 3, \"n_answers_per_question\": 5}\n",
    ")\n",
    "qa_dataset_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the dataset with an LLM critic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import union\n",
    "from llmops_rag.create_llm_filtered_dataset import apply_llm_critic, filter_dataset, prepare_dataset\n",
    "from llmops_rag.create_qa_dataset import QuestionAndAnswerDataset\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def create_llm_filtered_dataset(\n",
    "    dataset: union.FlyteFile = QuestionAndAnswerDataset.query(),\n",
    ") -> pd.DataFrame:\n",
    "    scores = apply_llm_critic(dataset)\n",
    "    reference_answers = filter_dataset(dataset, scores)\n",
    "    return prepare_dataset(reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = union.UnionRemote()\n",
    "filtered_dataset_execution = remote.execute(create_llm_filtered_dataset, inputs={})\n",
    "filtered_dataset_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š RAG Hyperparameter Optimization\n",
    "\n",
    "Experiment with different embedding models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import union\n",
    "from typing import Optional, Annotated\n",
    "from llmops_rag.optimize_rag import (\n",
    "    GridSearchConfig,\n",
    "    prepare_hpo_configs,\n",
    "    prepare_questions,\n",
    "    gridsearch,\n",
    "    combine_answers,\n",
    "    evaluate,\n",
    "    report,\n",
    ")\n",
    "from llmops_rag.config import RAGConfig\n",
    "from llmops_rag.create_llm_filtered_dataset import EvalDatasetArtifact\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def optimize_rag(\n",
    "    gridsearch_config: GridSearchConfig,\n",
    "    root_url_tags_mapping: Optional[dict] = None,\n",
    "    exclude_patterns: Optional[list[str]] = None,\n",
    "    limit: Optional[int] = 10,\n",
    "    eval_dataset: Annotated[pd.DataFrame, EvalDatasetArtifact] = EvalDatasetArtifact.query(dataset_type=\"llm_filtered\"),\n",
    "    eval_prompt_template: Optional[str] = None,\n",
    "    n_answers: int = 1,\n",
    ") -> RAGConfig:\n",
    "    hpo_configs = prepare_hpo_configs(gridsearch_config)\n",
    "    questions = prepare_questions(eval_dataset, n_answers)\n",
    "    answers = gridsearch(questions, hpo_configs, root_url_tags_mapping, exclude_patterns, limit)\n",
    "    answers_dataset = combine_answers(answers, hpo_configs, questions)\n",
    "    best_config, evaluation, evalution_summary = evaluate(\n",
    "        answers_dataset, eval_prompt_template\n",
    "    )\n",
    "    report(evaluation, evalution_summary)\n",
    "    return best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def run_experiment(config_path: str):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        gridsearch_config = GridSearchConfig(**yaml.safe_load(f))\n",
    "\n",
    "    remote = union.UnionRemote()\n",
    "    execution = remote.execute(optimize_rag, inputs={\"gridsearch_config\": gridsearch_config})\n",
    "    return execution\n",
    "\n",
    "\n",
    "run_experiment(\"config/embedding_model_experiment.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª More experiments to run (optional)\n",
    "\n",
    "Uncomment the code cells below to run different experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiment(\"config/prompt_experiment.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different chunksizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiment(\"config/chunksize_experiment.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different splitters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiment(\"config/splitter_experiment.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with reranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiment(\"config/reranking_experiment.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with document retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiment(\"config/search_params_experiment.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Putting it all together into a reactive pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Annotated\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import union\n",
    "import flytekit as fl\n",
    "from union.artifacts import OnArtifact\n",
    "\n",
    "from llmops_rag.document import CustomDocument\n",
    "from llmops_rag.create_qa_dataset import create_qa_dataset\n",
    "from llmops_rag.create_llm_filtered_dataset import create_llm_filtered_dataset, EvalDatasetArtifact\n",
    "from llmops_rag.image import image\n",
    "from llmops_rag.optimize_rag import optimize_rag, GridSearchConfig\n",
    "from llmops_rag.vector_store import create_knowledge_base as _create_knowledge_base\n",
    "\n",
    "\n",
    "# Clear the launch plan cache\n",
    "union.LaunchPlan.CACHE = {}\n",
    "\n",
    "\n",
    "KnowledgeBaseHPO = union.Artifact(name=\"knowledge-base-hpo\")\n",
    "\n",
    "\n",
    "@union.task(\n",
    "    container_image=image,\n",
    "    requests=union.Resources(cpu=\"2\", mem=\"8Gi\"),\n",
    "    enable_deck=True,\n",
    ")\n",
    "def create_knowledge_base_hpo(\n",
    "    root_url_tags_mapping: Optional[dict] = None,\n",
    "    limit: Optional[int | float] = None,\n",
    "    exclude_patterns: Optional[list[str]] = None,\n",
    ") -> Annotated[list[CustomDocument], KnowledgeBaseHPO]:\n",
    "    return _create_knowledge_base.task_function(\n",
    "        root_url_tags_mapping=root_url_tags_mapping,\n",
    "        limit=limit,\n",
    "        exclude_patterns=exclude_patterns,\n",
    "    )\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def knowledge_base_workflow(\n",
    "    root_url_tags_mapping: Optional[dict] = None,\n",
    "    limit: Optional[int | float] = None,\n",
    "    exclude_patterns: Optional[list[str]] = None,\n",
    ") -> list[CustomDocument]:\n",
    "    return create_knowledge_base_hpo(\n",
    "        root_url_tags_mapping=root_url_tags_mapping,\n",
    "        limit=limit,\n",
    "        exclude_patterns=exclude_patterns,\n",
    "    )\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def create_eval_dataset(\n",
    "    documents: list[CustomDocument],\n",
    "    n_questions_per_doc: int = 1,\n",
    "    n_answers_per_question: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    qa_dataset = create_qa_dataset(\n",
    "        documents=documents,\n",
    "        n_questions_per_doc=n_questions_per_doc,\n",
    "        n_answers_per_question=n_answers_per_question,\n",
    "    )\n",
    "    return create_llm_filtered_dataset(dataset=qa_dataset)\n",
    "\n",
    "\n",
    "knowledge_base_lp = union.LaunchPlan.get_or_create(\n",
    "    knowledge_base_workflow,\n",
    "    name=\"knowledge_base_lp\",\n",
    "    default_inputs={\"limit\": 10},\n",
    "    schedule=fl.FixedRate(duration=timedelta(minutes=2))\n",
    ")\n",
    "\n",
    "create_eval_dataset_lp = union.LaunchPlan.get_or_create(\n",
    "    create_eval_dataset,\n",
    "    name=\"create_eval_dataset_lp\",\n",
    "    trigger=OnArtifact(\n",
    "        trigger_on=KnowledgeBaseHPO,\n",
    "        inputs={\"documents\": KnowledgeBaseHPO.query()},\n",
    "    )\n",
    ")\n",
    "\n",
    "optimize_rag_lp = union.LaunchPlan.get_or_create(\n",
    "    optimize_rag,\n",
    "    name=\"optimize_rag_lp\",\n",
    "    default_inputs={\n",
    "        \"gridsearch_config\": GridSearchConfig(\n",
    "            embedding_model=[\n",
    "                \"text-embedding-ada-002\",\n",
    "                \"text-embedding-3-small\",\n",
    "                \"text-embedding-3-large\",\n",
    "            ],\n",
    "            chunk_size=[256],\n",
    "            splitter=[\"recursive\"],\n",
    "        ),\n",
    "    },\n",
    "    trigger=OnArtifact(\n",
    "        trigger_on=EvalDatasetArtifact,\n",
    "        inputs={\"eval_dataset\": EvalDatasetArtifact.query()},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = union.UnionRemote()\n",
    "\n",
    "version = \"workshop-v0\"\n",
    "registered_lps = []\n",
    "for lp in [\n",
    "    knowledge_base_lp,\n",
    "    create_eval_dataset_lp,\n",
    "    optimize_rag_lp,\n",
    "]:\n",
    "    registered_lp = remote.register_launch_plan(lp, version=version)\n",
    "    registered_lps.append(registered_lp)\n",
    "    remote.activate_launchplan(registered_lp.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deactivate the reactive pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for registered_lp in registered_lps:\n",
    "    remote.deactivate_launchplan(registered_lp.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
